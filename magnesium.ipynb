{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f1fa16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import utils\n",
    "import newEstimator as NE\n",
    "main_dir = \"C:/Users/nourisa/Downloads/testProjs/omics\"\n",
    "sys.path.insert(0,main_dir)\n",
    "specs = dict(\n",
    "    o_df_dir = os.path.join(main_dir,'data','original_omics.xlsx'),\n",
    "    df_dir = os.path.join(main_dir,'data','omics.csv'),\n",
    "    time = [1,2,3,4,7,8,9,10,11,14,21],\n",
    "    p_ID = 'Entry',  # The column name in the original data to be used as protein ID\n",
    "    c_tag = 'ctr_',\n",
    "    s_tag = 'mg_',\n",
    "    c_func = lambda t: 'ctr_' + str(t),  # The tag used in the tailored dataframe for control\n",
    "    s_func = lambda t: 'mg_' + str(t),  # The tag used in the tailored dataframe for sample\n",
    "    o_c_func = lambda t: 'LogLFQ intensity ' + str(t) + '_0',  # Func to extract the control data from the original database \n",
    "    o_s_func = lambda t: 'LogLFQ intensity ' + str(t) + '_1',  # Func to extract the sample data from the original database\n",
    "    ee = 0.5,  # Threshold for log2FC to retain the data\n",
    "    min_s = 2,  # Min occurance in time series in order to retain the data  \n",
    ")\n",
    "## read the original data\n",
    "o_df = pd.read_excel(specs['o_df_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0652ff34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining missing names:  []\n",
      "Data size, original: 2562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nourisa\\Downloads\\testProjs\\omics\\utils.py:114: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop(['index'],axis=1,inplace = True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size, rows with all zeros were removed: 2229\n",
      "Sig proteins:  34\n",
      "Sig proteins: 34\n",
      "Sig interpolated proteins: 34\n"
     ]
    }
   ],
   "source": [
    "# process the data\n",
    "o_df_m = utils.rename_missing_symbols(o_df,**specs); \n",
    "df = utils.tailor_names(o_df_m, **specs)\n",
    "df = utils.remove_zeros(df, **specs)\n",
    "# extract sig proteins\n",
    "df_sig = utils.sig_df(df, **specs)\n",
    "print('Sig proteins: {}'.format(len(df_sig)))\n",
    "# impute missing values: available techniques to try: interpolate, univariate and multivariate: https://scikit-learn.org/stable/modules/impute.html\n",
    "df_interp = df_sig.interpolate() \n",
    "df_interp = utils.listwise_deletion(df_interp)\n",
    "print('Sig interpolated proteins: {}'.format(len(df_interp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6077de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats of sig proteins: different time points, unknown proteins\n",
    "\n",
    "# number of sig proteins for different time points\n",
    "sig_prot_names = {} \n",
    "for day in specs['time']:\n",
    "    sig_prot_names[day] = utils.sig_test(df,day,**specs)[specs['p_ID']].tolist()\n",
    "# plot number of sig proteins for measurement times \n",
    "fig, axes = plt.subplots(figsize = (15,4), nrows = 1, ncols = 3, tight_layout = True)\n",
    "def plot_stats_time_1(ax):\n",
    "    ax.bar(range(len(sig_prot_names)),[len(x) for x in sig_prot_names.values()])\n",
    "    ax.set_ylabel('Number of proteins')\n",
    "    ax.set_xlabel('Measurement day')\n",
    "    ax.set_xticks(range(len(sig_prot_names)))\n",
    "    _ = ax.set_xticklabels(sig_prot_names.keys())\n",
    "    ax.set_title('Differentially expressed proteins')\n",
    "plot_stats_time(axes[0])\n",
    "#------\n",
    "# sig incidence number: how many times a protein is detected sig across different time points\n",
    "limit_n = 3 # if the incidences are below this, dont plot it\n",
    "sig_prots_e = [x for xx in sig_prot_names.values() for x in xx] # duplicates included\n",
    "sig_prots = list(set(sig_prots_e)) # duplicates excluded\n",
    "print('Number of prots upregulated in at least one time point: ',len(sig_prots))\n",
    "sig_prots_i = {i:sig_prots_e.count(i) for i in sig_prots} # incidences \n",
    "sig_prots_i_f = {}\n",
    "for key,value in sig_prots_i.items():\n",
    "    if value >= limit_n:\n",
    "        sig_prots_i_f[key] = value\n",
    "print('Number of prots upregulated in at least 3 time points: ',len(sig_prots_i_f))\n",
    "def plot_stats_time_2(ax):\n",
    "    ax.bar(range(len(sig_prots_i_f)),sig_prots_i_f.values())\n",
    "    ax.set_ylabel('Number of incidences')\n",
    "    ax.set_xlabel('Measurement day')\n",
    "    ax.set_xticks(range(len(sig_prots_i_f)))\n",
    "    ax.set_xticklabels(sig_prots_i_f.keys())\n",
    "    ax.set_title('Multiple differentially expressed proteins')\n",
    "plot_stats_time_2(axes[1])\n",
    "#----\n",
    "# sig incidence number for unknown params\n",
    "unknown_sigs_prots = [x for x in sig_prots if 'p_' in x ]\n",
    "unknown_sigs_prots_i = {i:sig_prots_e.count(i) for i in unknown_sigs_prots} # incidences \n",
    "print('Total number of unknown paramters: ',len([x for x in df[specs['p_ID']].tolist() if 'p_' in x ]))\n",
    "print('Sig number of unknown paramters: ',len(unknown_sigs_prots))\n",
    "def plot_stats_time_3(ax):\n",
    "    ax.bar(range(len(unknown_sigs_prots_i)),unknown_sigs_prots_i.values())\n",
    "    ax.set_ylabel('Number of incidences')\n",
    "    ax.set_xticks(range(len(unknown_sigs_prots_i)))\n",
    "    _ = ax.set_xticklabels(unknown_sigs_prots_i.keys())\n",
    "    ax.set_title('Multiple differentially expressed proteins')\n",
    "plot_stats_time_3(axes[2])\n",
    "#----\n",
    "# output the name of sig proteins \n",
    "def remove_unknown(sig_prot_names):\n",
    "    sig_prots_time_f = {}\n",
    "    for key,values in sig_prot_names.items():\n",
    "        values_f = [x for x in values if x != np.nan]\n",
    "        _str = ''\n",
    "        for value in values_f:\n",
    "            _str += value + '\\n'\n",
    "        sig_prots_time_f[key] = _str\n",
    "    return sig_prots_time_f\n",
    "sig_prots_time_f = remove_unknown(sig_prot_names)\n",
    "with open('results/sig_prots.txt','w') as f:\n",
    "    for key,value in sig_prots_time_f.items():\n",
    "        f.write('\\n \\nday '+ str(key)+': \\n'+ value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f9876fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_exp n: 2\n",
      "n_time*n_genes (11, 34)\n"
     ]
    }
   ],
   "source": [
    "# reformat the data for time series\n",
    "df_target = df_interp\n",
    "time = specs['time']\n",
    "p_ID = specs['p_ID']\n",
    "data_ctr = np.array(df_target.loc[:,['ctr_'+str(day) for day in time]].values)\n",
    "data_mg = np.array(df_target.loc[:,['mg_'+str(day) for day in time]].values)\n",
    "(TS_data, time_points, decay_rates, gene_names) = \\\n",
    "    [data_ctr.transpose(),data_mg.transpose()], [time,time],[],df_target[p_ID].tolist()\n",
    "print('n_exp n:',len(TS_data))\n",
    "print('n_time*n_genes',TS_data[0].shape)\n",
    "\n",
    "# convert data to n_samples*n_genes format\n",
    "Xs,ys = NE.process_data(TS_data, time_points, regulators = 'all',alpha='from_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7ed6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## grid search\n",
    "import newEstimator \n",
    "import importlib\n",
    "import numpy as np\n",
    "importlib.reload(newEstimator)\n",
    "param = dict(\n",
    "    estimator_t = 'RF', \n",
    "    n_estimators = 100,\n",
    "    oob_score = True\n",
    ")\n",
    "param_grid = dict(\n",
    "    max_depth = [10,30],\n",
    "    n_estimators = [20,50,150]\n",
    ")\n",
    "specs = dict(\n",
    "    n_jobs = 10,\n",
    "#     cv = 5,\n",
    "    use_oob_score = True,\n",
    ")\n",
    "best_scores, best_params, best_ests = newEstimator.grid_search(Xs, ys, param, param_grid, **specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6acd641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# network inference after training\n",
    "import importlib\n",
    "import newEstimator\n",
    "import utils as ul\n",
    "importlib.reload(utils)\n",
    "\n",
    "ests, scores_train, links = newEstimator.network_inference(Xs, ys, ests = best_ests)\n",
    "ul.plot_hist(xs = [scores_train,best_scores], names = ['train', 'test'])\n",
    "print('train -> mean: %.3f, std: %.3f'%(np.mean(scores_train),np.std(scores_train)))\n",
    "print('test -> mean: %.3f, std: %.3f'%(np.mean(best_scores),np.std(best_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10295019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# network inference with no training\n",
    "import importlib\n",
    "import newEstimator\n",
    "import utils as ul\n",
    "importlib.reload(newEstimator)\n",
    "param = dict(\n",
    "    estimator_t = 'RF', \n",
    "    n_estimators = 100,\n",
    "    oob_score = True\n",
    ")\n",
    "ests, scores_train, links, oob_scores = newEstimator.network_inference(Xs, ys, param = param)\n",
    "ul.plot_hist(xs = [scores_train,best_scores], names = ['train', 'test'])\n",
    "print('train -> mean: %.3f, std: %.3f'%(np.mean(scores_train),np.std(scores_train)))\n",
    "print('test -> mean: %.3f, std: %.3f'%(np.mean(oob_scores),np.std(oob_scores)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
