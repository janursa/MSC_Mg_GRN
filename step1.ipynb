{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1af4015",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "288ce8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import math\n",
    "import json\n",
    "from scripts import utils\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "MAIN_DIR = \"C:/Users/nourisa/Downloads/testProjs/proteomics_MSC\"\n",
    "IMPUT_FILE = os.path.join(MAIN_DIR,'statistical_analysis_2/ProteinAbundance_tables/ProtAbundance__Norm_n_Imp_SVD.csv') # dir for the imputated df \n",
    "SIG_FILE = os.path.join(MAIN_DIR, 'statistical_analysis_2/DiffExp_tables/TopTable_TimeCourse_SVD.csv') # dir for the sig analysis\n",
    "OUTPUT_DIR = os.path.join(MAIN_DIR,'results')\n",
    "sys.path.insert(0,MAIN_DIR)\n",
    "specs = dict(\n",
    "    o_df_dir = os.path.join(MAIN_DIR,'data','original_omics.xlsx'),\n",
    "    df_dir = os.path.join(MAIN_DIR,'data','primary_omics.csv'),\n",
    "    time = [1,2,3,4,7,8,9,10,11,14,21],\n",
    "    p_name = 'Entry',  # The column name in the original data to be used as protein name\n",
    "    c_tag = 'ctr_',\n",
    "    s_tag = 'mg_',\n",
    "    c_func = lambda t: 'ctr_' + str(t),  # The tag used in the tailored dataframe for control\n",
    "    s_func = lambda t: 'mg_' + str(t),  # The tag used in the tailored dataframe for sample\n",
    "    o_c_func = lambda t: 'LogLFQ intensity ' + str(t) + '_0',  # Func to extract the control data from the original database \n",
    "    o_s_func = lambda t: 'LogLFQ intensity ' + str(t) + '_1',  # Func to extract the sample data from the original database\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a22e1d",
   "metadata": {},
   "source": [
    "# Edit the original df to create primary df \n",
    "Read the original proteomics data, process it by:\n",
    "renaming the missing symbols\n",
    "changing column names (to make it easier to follow)\n",
    "removing rows with all zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1fa16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils)\n",
    "## read the original data \n",
    "o_df = pd.read_excel(specs['o_df_dir'])\n",
    "# process the data\n",
    "o_df_m = utils.rename_missing_symbols(o_df,**specs); \n",
    "df = utils.tailor_names(o_df_m, **specs)\n",
    "df = utils.remove_zeros(df, **specs)\n",
    "df.to_csv(specs['df_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8dc58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nonStrIndices = [type(item) != str for item in df['Gene']]\n",
    "# df.loc[nonStrIndices,'Entry']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35c2547",
   "metadata": {},
   "source": [
    "# Post statistical analysis\n",
    "- Read imputed and DE results, and sort them based on protein names\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3370c4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the imputed df\n",
    "df_imput = pd.read_csv(IMPUT_FILE)\n",
    "df_imput.rename(columns={'Unnamed: 0':'Protein'},inplace=True)\n",
    "# read the sig results\n",
    "df_sig = pd.read_csv(SIG_FILE)\n",
    "# sort the data to make them comparable\n",
    "df_imput.sort_values('Protein', inplace=True)\n",
    "df_imput.reset_index(drop=True, inplace=True)\n",
    "df_sig.sort_values('Protein', inplace=True)\n",
    "df_sig.reset_index(drop=True, inplace=True)\n",
    "prots_names = df_sig['Protein'].values\n",
    "# calculate fold change: log(mg)-log(ctr)\n",
    "df_diff = pd.DataFrame() #columns: ['Protein','1','2', etc (time points)]\n",
    "df_diff['Protein'] = df_imput['Protein']\n",
    "for t in specs['time']:\n",
    "    ctr = f'ctr_{t}'\n",
    "    mg = f'mg_{t}'\n",
    "    df_diff[t] = (df_imput.loc[:,mg]-df_imput.loc[:,ctr]).values\n",
    "# select \n",
    "DE_t = .05\n",
    "fold_change_t = 1.5\n",
    "df_flags = pd.DataFrame()#columns=['Protein','Sig','FC_1','FC_2',etc,'Overall']\n",
    "df_flags['Protein'] = df_imput['Protein']\n",
    "df_flags['Sig'] = df_sig['P.Value']<DE_t\n",
    "for t in specs['time']:\n",
    "    tag = f'FC_{t}'\n",
    "    df_flags[tag] = abs(df_diff[t]) > np.log2(fold_change_t)\n",
    "df_flags['DE'] = df_flags['Sig']* np.any(df_flags.iloc[0:,2:].values,axis=1)\n",
    "# output the DE proteins to a file\n",
    "DE_protnames = list(df_flags.loc[df_flags['DE'],'Protein'].values)\n",
    "DE_protnames_str = ''\n",
    "for gene in DE_protnames:\n",
    "    DE_protnames_str+=gene + ','\n",
    "with open(os.path.join(MAIN_DIR,'results/postprocess','DE_protnames.txt'),'w') as f:\n",
    "    print({'DE_protnames':DE_protnames, 'DE_protnames_str':DE_protnames_str}, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6cb3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# volcanic plot: -log10(p values) vs log2(foldchange)\n",
    "# import matplotlib.pyplot as plt\n",
    "# sig_cut_off = -np.log10(.05)\n",
    "# FC_cut_off = np.log2(1.5)\n",
    "# # calculate log10(p-values)\n",
    "# negLog10pv = -np.log10(list(df_SA_sort['P.Value'].values))\n",
    "# # calculate log2 fold change (log(mg)-log(ctr)). The average of different time was taken into account \n",
    "# df_diff = pd.DataFrame()\n",
    "# df_diff['Entry'] = df_imput['Entry']\n",
    "# for t in specs['time']:\n",
    "#     ctr = f'ctr_{t}'\n",
    "#     mg = f'mg_{t}'\n",
    "#     df_diff[t] = (df_imput_sort.loc[:,mg]-df_imput_sort.loc[:,ctr]).values\n",
    "\n",
    "# # flags: to find those passing the thresholds\n",
    "# sig_flags = negLog10pv>=sig_cut_off\n",
    "# FC_flags = abs(df_diff.iloc[0:,1:].values)>FC_cut_off \n",
    "# flags = FC_flags * sig_flags[:,None] # n_genes*n_days\n",
    "# # select those with at least one FC>threshold across different time points\n",
    "# flags_a = [np.any(row) for row in flags]\n",
    "# sig_indices = [i for i in range(len(flags_a)) if flags_a[i]]\n",
    "# sigs_prot = df_imput_sort.loc[sig_indices,'Entry'].values\n",
    "# print('number of sig proteins: ', len(sig_prots))\n",
    "# # extract df with sig diff\n",
    "# df_sig = df_imput_sort.loc[df_imput_sort['Entry'].isin(sigs_prots)]\n",
    "# df_sig.to_csv('results/statAnalysis/df_sig.csv',index=False)\n",
    "# # create df for the selected proteins\n",
    "# df_chosen = df_diff.loc[df_diff['Entry'].isin(sig_prots),:]\n",
    "# df_chosen.columns=['Protein']+[f'FC (Day {t})' for t in specs['time']]\n",
    "# df_chosen.loc[:,'P-Value'] = df_SA_sort.loc[df_SA_sort['Entry'].isin(sig_prots),'P.Value'].values\n",
    "# df_chosen = df_chosen.sort_values('P-Value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963ede5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# volcanic plot: -log10(p values) vs log2(foldchange)\n",
    "class Plot:\n",
    "    linewidth = 2\n",
    "    max_diff = np.max(df_diff.iloc[0:,1:].values)\n",
    "    fold_change_line = np.log2(fold_change_t)\n",
    "    @staticmethod\n",
    "    def mark_p_value(ax,sig_cut_off):\n",
    "        \"\"\"\n",
    "        Markline for the sig\n",
    "        \"\"\"\n",
    "        line_color = 'grey'\n",
    "        dx = ax.get_xlim()\n",
    "        ax.axhline(sig_cut_off,color='grey', linestyle='-.')\n",
    "    @staticmethod\n",
    "    def mark_FC(ax,FC_cut_off):\n",
    "        \"\"\"\n",
    "        Markline for fold change\n",
    "        \"\"\"\n",
    "        line_color = 'grey'\n",
    "        FC_cut_offs = [-FC_cut_off,FC_cut_off]\n",
    "        for FC_cut_off in FC_cut_offs:\n",
    "            ax.axvline(FC_cut_off,color=line_color, linestyle='--',linewidth=Plot.linewidth)\n",
    "    @staticmethod\n",
    "    def scatter(ax,log2FC,negLog10pv,flags):\n",
    "        ax.scatter(log2FC,negLog10pv,\n",
    "                   color=['red' if flag else 'black' for flag in flags],\n",
    "#                    alpha=[1 if flag else .5 for flag in flags]\n",
    "                   alpha = .7,\n",
    "                   linewidths=.5,\n",
    "                   edgecolors='cyan'\n",
    "                  )\n",
    "    def print_names(ax, log2FC, flag):\n",
    "        fontsize = 7\n",
    "        log2FC_s = log2FC[flag].values\n",
    "        gene_names_s = df_flags.loc[flag, 'Protein']\n",
    "        sign_flag = log2FC_s>=0\n",
    "        gene_names_right = gene_names_s[sign_flag]\n",
    "        gene_names_negative = gene_names_s[~sign_flag]\n",
    "        for i, name in enumerate(gene_names_right):\n",
    "            ax.annotate(name,(1.37,3.4-.3*i),fontsize=fontsize)\n",
    "        for i, name in enumerate(gene_names_negative):\n",
    "            ax.annotate(name,(-1.75,3.4-.3*i),fontsize=fontsize)\n",
    "#         ax.annotate(text_right, (1.1,1),fontsize=fontsize)\n",
    "    @staticmethod\n",
    "    def postprocess(ax,time):\n",
    "        ax.set_xlabel('Log₂ (fold-change)')\n",
    "        ax.set_ylabel('- Log₁₀ (p-value)')\n",
    "        ax.set_xlim([-1.3*Plot.max_diff, 1.3*Plot.max_diff])\n",
    "        ax.set_title(f'Day {time}')\n",
    "        ax.set_xticks([-Plot.max_diff,-Plot.fold_change_line,int(0),Plot.fold_change_line, Plot.max_diff])\n",
    "        ax.set_xticklabels([-round(Plot.max_diff,2),-round(Plot.fold_change_line,2),int(0),round(Plot.fold_change_line,2),round(Plot.max_diff,2)])\n",
    "def plot_multiple(axes, days, cols):\n",
    "    for i, time in enumerate(days):\n",
    "        ax = axes[int(i/cols)][i%cols]\n",
    "        log2FC = df_diff[time]\n",
    "        negLog10pv = -np.log10(df_sig['P.Value'].values)\n",
    "        DE_flags_time = (df_flags['Sig'] * df_flags[f'FC_{time}']).values \n",
    "        Plot.scatter(ax,log2FC,negLog10pv, DE_flags_time)\n",
    "        Plot.mark_p_value(ax,-np.log10(sig_t))\n",
    "        Plot.mark_FC(ax,np.log2(fold_change_t))\n",
    "        Plot.postprocess(ax,time)\n",
    "        Plot.print_names(ax,log2FC,DE_flags_time)\n",
    "def plot_selected():\n",
    "    days = [1,3,10,14]\n",
    "    rows = 2\n",
    "    cols = 2\n",
    "    fig, axes = plt.subplots(rows, cols, tight_layout=True, figsize=(cols*4, rows*3))\n",
    "    plot_multiple(axes, days, cols)\n",
    "    fig.savefig(os.path.join(OUTPUT_DIR,'statAnalysis','volcanic_selected.pdf'))\n",
    "    fig.savefig(os.path.join(OUTPUT_DIR,'statAnalysis','volcanic_selected.png'),facecolor='white',dpi=300)\n",
    "\n",
    "def plot_all():\n",
    "    rows = 6\n",
    "    cols = 2\n",
    "    fig, axes = plt.subplots(rows, cols, tight_layout=True, figsize=(cols*4, rows*3))\n",
    "    plot_multiple(axes, specs['time'], cols)\n",
    "    fig.savefig(os.path.join(OUTPUT_DIR,'statAnalysis','volcanic_all.pdf'))\n",
    "    fig.savefig(os.path.join(OUTPUT_DIR,'statAnalysis','volcanic_all.png'),facecolor='white',dpi=300)\n",
    "# plot_all()\n",
    "plot_selected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbf956f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot table of FC and pvalues: TODO:this needs work\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "fig, ax = plt.subplots(1, 1, tight_layout=True, figsize=(4, 3))\n",
    "fig.patch.set_visible(False)\n",
    "ax.axis('off')\n",
    "ax.axis('tight')\n",
    "df_chosen = df_chosen.iloc[0:10,:]\n",
    "df_chosen_r = df_chosen.round(4)\n",
    "table= plt.table(cellText=df_chosen_r.values, colLabels=df_chosen_r.columns, loc='center')\n",
    "from matplotlib.font_manager import FontProperties\n",
    "for (row, col), cell in table.get_celld().items():\n",
    "    if (row == 0):\n",
    "        cell.set_text_props(fontproperties=FontProperties(weight='bold'))\n",
    "fig.savefig(os.path.join(OUTPUT_DIR,'table.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ec663d",
   "metadata": {},
   "source": [
    "# Enrichment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2036768f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched: 48 / 48\n"
     ]
    }
   ],
   "source": [
    "# convert differnt gene annotation to one another. protname (UniProt name), genename,\n",
    "# geneID (entrenz gene id). https://www.uniprot.org/id-mapping/ \n",
    "from scripts import annotaion_map\n",
    "import json\n",
    "importlib.reload(annotaion_map)\n",
    "with open(os.path.join(MAIN_DIR, 'results/postprocess','DE_protnames.txt')) as f:\n",
    "    DE_protnames = eval(f.read())['DE_protnames']\n",
    "\n",
    "map_protname_geneID = annotaion_map.protname_geneID(DE_protnames)\n",
    "with open(os.path.join(MAIN_DIR,'results/postprocess','map_protname_geneID.json'),'w') as f:\n",
    "    f.write(json.dumps({'map':map_protname_geneID}))\n",
    "# map protname to genename according to string: because it is different using the website\n",
    "string_map = pd.read_csv(os.path.join(MAIN_DIR,'results/enrichment_analysis/string/string_mapping.tsv'), sep='\\t',index_col=False)\n",
    "map_protname_genename = {key:value for key,value in zip(string_map['queryItem'], string_map['preferredName'])}\n",
    "with open(os.path.join(MAIN_DIR,'results/postprocess','map_protname_genename.json'),'w') as f:\n",
    "    f.write(json.dumps({'map':map_protname_genename}))\n",
    "# rest\n",
    "map_genename_protname = {value:key for value, key in zip(map_protname_genename.values(),map_protname_genename.keys())}\n",
    "with open(os.path.join(MAIN_DIR,'results/postprocess','map_genename_protname.json'),'w') as f:\n",
    "    f.write(json.dumps({'map':map_genename_protname}))\n",
    "map_genename_geneID = {key:map_protname_geneID[value] for key, value in map_genename_protname.items()}\n",
    "with open(os.path.join(MAIN_DIR,'results/postprocess','map_genename_geneID.json'),'w') as f:\n",
    "    f.write(json.dumps({'map':map_genename_geneID}))\n",
    "# write geneIDs to a file\n",
    "with open(os.path.join(MAIN_DIR, 'results/postprocess','DE_geneIDs.json'),'w') as f:\n",
    "    f.write(json.dumps({'geneIDs':list(map_protname_geneID.values())}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08ac707",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec19e67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# format strings enrichment data  for R    \n",
    "def reireive_string_data_F(file_type):\n",
    "    '''\n",
    "        Reads string EA data such as enrichment.Function\n",
    "    '''\n",
    "    FILE =  os.path.join(os.path.join(MAIN_DIR, 'results/enrichment_analysis/string'),file_type)\n",
    "    data = pd.read_csv(FILE,sep='\\t',index_col=False)\n",
    "    # remove some columns\n",
    "    data.drop('matching proteins in your network (IDs)',axis=1,inplace=True) \n",
    "    data.drop('background gene count',axis=1,inplace=True) \n",
    "    data.columns = ['ID','Description', 'Count', 'Strength','p.adjust','genenames']\n",
    "    # set gene ratio is in the format of x/total\n",
    "    GeneRatio = []\n",
    "    for item in data['Count']:\n",
    "        GeneRatio.append(str(item)+'/'+str(len(DE_protnames)))\n",
    "    data.loc[:,'GeneRatio'] = GeneRatio\n",
    "    # not useful but required as input to the graph\n",
    "    data['pvalue'] = data['p.adjust'] \n",
    "    data['qvalue'] = data['pvalue'] \n",
    "    data['BgRatio'] = data['GeneRatio'] #TODO: fix this\n",
    "    # change the gene names to gene ID\n",
    "    geneIDs_list = []\n",
    "    for genenames in data['genenames']:\n",
    "        geneIDs = [map_genename_geneID[genename] for genename in genenames.split(',')]\n",
    "        geneIDs_str = '/'.join(geneIDs)\n",
    "        geneIDs_list.append(geneIDs_str)\n",
    "        \n",
    "    data.loc[:,'geneID'] = geneIDs_list\n",
    "    data.drop('genenames', axis=1, inplace=True)\n",
    "    data.drop('Strength', axis=1, inplace=True) #TODO: fix this\n",
    "    return data\n",
    "data = reireive_string_data_F('enrichment.Process.tsv')\n",
    "data.to_csv(os.path.join(MAIN_DIR,'results/postprocess','enrichment_process.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f566c495",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_clusters = pd.read_csv(os.path.join(MAIN_DIR,'string','string_MCL_clusters.tsv'),sep='\\t')\n",
    "df_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961595e2",
   "metadata": {},
   "source": [
    "# Noncategorized "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7e0eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the time series of sig prots\n",
    "utils.plot_time_series(df, prots=sig_prots, c_tag='ctr_', s_tag='mg_', p_ID='Entry', time=specs['time'], ee=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a6eafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the sig proteins for original and imputed versions\n",
    "from scripts import utils\n",
    "candids = sig_prots[0:10]\n",
    "utils.plot_time_series_mutual(df1=df,df2=df_imput, prots=candids, )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f26d949",
   "metadata": {},
   "source": [
    "plot time serties of Moreneo's sig prots and check which ones are detected in our analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5ad14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts import utils\n",
    "importlib.reload(utils)\n",
    "moreneo_sigs = ['SDF4','NUFIP2','BUB3','HMGA2','KIF5B','DYNC1I2','DCTN1','S100A10','SYNPO2','MARCKS','THY1','HUWE1','PRPF8','RPS18','GCN1L1','RPL14','RBM8A','RPL23A','CANX','DLST','PDHB','ALDOC','APOA1','GGH','UAP1','ENO2','BAG3','HNRNPAB','BASP1','THRAP3','LRPPRC','CSE1L','PABPC4']\n",
    "utils.plot_time_series(df, prots=moreneo_sigs[0:len(moreneo_sigs)], c_tag='ctr_', s_tag='mg_', p_ID='Gene', time=specs['time'], ee=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7af932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the overlap between Moreneo's sig prots and this study\n",
    "df_overlap = df_sig.loc[df_sig['Gene'].isin(moreneo_sigs)]\n",
    "prots_overlap = df_overlap['Entry'].values\n",
    "print(prots_overlap)\n",
    "# utils.plot_time_series(df, prots=prots_overlap, c_tag='ctr_', s_tag='mg_', p_ID='Gene', time=specs['time'], ee=0.5)\n",
    "# print(prots_overlap)\n",
    "df_sig.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3fe58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputing code\n",
    "import copy\n",
    "def KNNImputer(df, n_neighbors=2): #TODO: n neighbors should be evaluated\n",
    "    from sklearn import impute\n",
    "    df_copy = copy.deepcopy(df)\n",
    "    data = df[[f'ctr_{i}' for i in time]+[f'mg_{i}' for i in time]].values\n",
    "    imputer = impute.KNNImputer(n_neighbors=n_neighbors)\n",
    "    new_data = imputer.fit_transform(data)\n",
    "    df_copy[[f'ctr_{i}' for i in time]+[f'mg_{i}' for i in time]] = new_data\n",
    "    return df_copy\n",
    "df_imput = KNNImputer(df) #TODO: this can be experimented\n",
    "for gene in df_imput['Entry'].values:\n",
    "    if df_imput.loc[df_imput['Entry']==gene].isna().values.any():\n",
    "        print('still missing values: ', gene)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
