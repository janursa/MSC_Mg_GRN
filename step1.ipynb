{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1af4015",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288ce8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import math\n",
    "import json\n",
    "from scripts import utils\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "MAIN_DIR = \"C:/Users/nourisa/Downloads/testProjs/proteomics_MSC\"\n",
    "SIG_FILE = os.path.join(MAIN_DIR, 'statistical_analysis_2/DiffExp_tables/TopTable_TimeCourse_SVD.csv') # dir for the sig analysis\n",
    "OUTPUT_DIR = os.path.join(MAIN_DIR,'results')\n",
    "STATANALYSIS = os.path.join(OUTPUT_DIR,'statAnalysis')\n",
    "sys.path.insert(0,MAIN_DIR)\n",
    "\n",
    "#- which \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a22e1d",
   "metadata": {},
   "source": [
    "# Edit the original df to create primary df \n",
    "Read the original proteomics data, process it by:\n",
    "renaming the missing symbols\n",
    "changing column names (to make it easier to follow)\n",
    "removing rows with all zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1fa16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run scripts/edit_data/edit.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35c2547",
   "metadata": {},
   "source": [
    "# Post statistical analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f0b43fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    }
   ],
   "source": [
    "%run scripts/post_statistical_analysis/process.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ec663d",
   "metadata": {},
   "source": [
    "# Enrichment analysis\n",
    "Run this when entichment analysis (STRING) data is available"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94257101",
   "metadata": {},
   "source": [
    "## convert differnt gene annotation to one another. protname (UniProt name) and genename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2036768f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# geneID (entrenz gene id). https://www.uniprot.org/id-mapping/ \n",
    "from scripts import annotaion_map\n",
    "import json\n",
    "importlib.reload(annotaion_map)\n",
    "importlib.reload(utils)\n",
    "with open(os.path.join(MAIN_DIR, 'results/postprocess','DE_protnames.txt')) as f:\n",
    "    DE_protnames = eval(f.read())['DE_protnames']\n",
    "\n",
    "map_protname_geneID = annotaion_map.protname_geneID(DE_protnames)\n",
    "with open(os.path.join(MAIN_DIR,'results/postprocess','map_protname_geneID.json'),'w') as f:\n",
    "    f.write(json.dumps({'map':map_protname_geneID}))\n",
    "# map protname to genename according to string: because it is different using the website\n",
    "string_map = pd.read_csv(os.path.join(MAIN_DIR,'results/enrichment_analysis/string_mapping.tsv'), sep='\\t',index_col=False)\n",
    "map_protname_genename = {key:value for key,value in zip(string_map['queryItem'], string_map['preferredName'])}\n",
    "# check if string imported all protnames successfully\n",
    "try:\n",
    "    assert(len(map_protname_genename)==len(DE_protnames))\n",
    "except:\n",
    "    for prot in DE_protnames:\n",
    "        if prot not in string_map['queryItem'].values:\n",
    "            print(f'prot {prot} was not mapped in string')\n",
    "with open(os.path.join(MAIN_DIR,'results/postprocess','map_protname_genename.json'),'w') as f:\n",
    "    f.write(json.dumps({'map':map_protname_genename}))\n",
    "# rest\n",
    "map_genename_protname = {value:key for value, key in zip(map_protname_genename.values(),map_protname_genename.keys())}\n",
    "with open(os.path.join(MAIN_DIR,'results/postprocess','map_genename_protname.json'),'w') as f:\n",
    "    f.write(json.dumps({'map':map_genename_protname}))\n",
    "map_genename_geneID = {key:map_protname_geneID[value] for key, value in map_genename_protname.items()}\n",
    "with open(os.path.join(MAIN_DIR,'results/postprocess','map_genename_geneID.json'),'w') as f:\n",
    "    f.write(json.dumps({'map':map_genename_geneID}))\n",
    "# write geneIDs to a file\n",
    "with open(os.path.join(MAIN_DIR, 'results/postprocess','DE_geneIDs.json'),'w') as f:\n",
    "    f.write(json.dumps({'geneIDs':list(map_protname_geneID.values())}))\n",
    "# write genenames to a file\n",
    "DE_genenames = list(map_protname_genename.values())\n",
    "DE_genenames_str = \"\"\n",
    "for gene in DE_genenames:\n",
    "    DE_genenames_str+=gene + \",\"\n",
    "with open(os.path.join(MAIN_DIR,'results/postprocess','DE_genenames.json'),'w') as f:\n",
    "    json.dump({\"DE_genenames\":DE_genenames},f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c592490f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95087257",
   "metadata": {},
   "source": [
    "## format strings enrichment data  for plotting \n",
    "to plot enrichment results in r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec19e67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reireive_string_data_F(enrich_type):\n",
    "    '''\n",
    "        Reads string EA data such as enrichment.Function\n",
    "    '''\n",
    "    FILE =  os.path.join(MAIN_DIR, 'results/enrichment_analysis/enrichment.all.tsv')\n",
    "    data = pd.read_csv(FILE,sep='\\t',index_col=False)\n",
    "    # keep the specified enrichment type\n",
    "    filter_ = data.loc[:,'#category'] == enrich_type\n",
    "    data = data.loc[filter_,:]\n",
    "    data.drop('#category',axis=1, inplace=True)\n",
    "    # remove some columns\n",
    "    data.drop('matching proteins in your network (IDs)',axis=1,inplace=True) \n",
    "    data.drop('background gene count',axis=1,inplace=True)\n",
    "    # replace string gene name with uniprotname\n",
    "    data.columns = ['ID','Description', 'ProteinCount', 'Strength','FDR','genenames']\n",
    "    unitprotnames = []\n",
    "    for row in data['genenames']:\n",
    "        a = ''\n",
    "        for item in row.split(','):\n",
    "            a+=map_genename_protname[item]+','\n",
    "        unitprotnames.append(a[0:-1])\n",
    "    data['genenames'] = unitprotnames\n",
    "    data.loc[:,'ProteinRatio'] = data['ProteinCount']/len(DE_protnames)\n",
    "    # not useful but required as input to the graph\n",
    "    data['pvalue'] = data['FDR'] \n",
    "    data['qvalue'] = data['pvalue'] \n",
    "    data.rename(columns={'genenames':'geneID'}, inplace=True)\n",
    "    cut_t = 40\n",
    "    short_descript = []\n",
    "    for item in data.loc[:,'Description']:\n",
    "        if len(item)>cut_t:\n",
    "            aa =  item[0:cut_t] + '...'\n",
    "        else:\n",
    "            aa = item\n",
    "        short_descript.append(aa)\n",
    "    return data\n",
    "data_process = reireive_string_data_F('GO Process')\n",
    "data_process.to_csv(os.path.join(OUTPUT_DIR,'enrichment_analysis','enrichment_process.csv'),index=False)\n",
    "print('number of enriched process tersm ',len(data_process))\n",
    "\n",
    "data_function = reireive_string_data_F('GO Function')\n",
    "data_function.to_csv(os.path.join(OUTPUT_DIR,'enrichment_analysis','enrichment_function.csv'),index=False)\n",
    "print('number of enriched function tersm ',len(data_function))\n",
    "\n",
    "data_component = reireive_string_data_F('GO Component')\n",
    "data_component.to_csv(os.path.join(OUTPUT_DIR, 'enrichment_analysis','enrichment_component.csv'),index=False)\n",
    "print('number of enriched component tersm ',len(data_component))\n",
    "\n",
    "data_uniprot = reireive_string_data_F('UniProt Keywords')\n",
    "data_uniprot.to_csv(os.path.join(OUTPUT_DIR, 'enrichment_analysis','enrichment_keyword.csv'))\n",
    "print('number of enriched UniProt keywords terms ',len(data_uniprot))\n",
    "\n",
    "data_reactome = reireive_string_data_F('Reactome')\n",
    "data_reactome.to_csv(os.path.join(OUTPUT_DIR, 'enrichment_analysis','enrichment_reactome.csv'))\n",
    "print('number of enriched Reactome tersm ',len(data_reactome))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7dfcba4",
   "metadata": {},
   "source": [
    "## plot enriched terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277432f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "importlib.reload(utils)\n",
    "#- assignments\n",
    "size_tag = 'Strength'\n",
    "color_tag = 'FDR'\n",
    "xlabel = 'ProteinCount'\n",
    "#- data and their names\n",
    "datas_1 = [data_process]\n",
    "tags_1 = ['GO: Process'] # also shape tag\n",
    "marker_types_1= ['o']\n",
    "datas_2 = [data_component]\n",
    "tags_2 = ['GO: Component'] # also shape tag\n",
    "marker_types_2= ['o']\n",
    "datas_3 = [data_function, data_uniprot, data_reactome]\n",
    "tags_3 = ['GO: Biological Function', 'UniProt Keyword', 'Reactome Pathways'] # also shape tag\n",
    "marker_types_3= ['*', 's', 'p']\n",
    "\n",
    "fig = utils.enrichplotplot(datas_1, tags_1, size_t, color_t, xlabel, marker_types_1, figsize=(6.2,5), legend_color=True,legend_size=True, legend_marker=False,title='GO: Biological Process')\n",
    "fig.savefig(os.path.join(OUTPUT_DIR, 'enrichment_analysis', 'biological_process.png'), dpi=300, transparent=True)\n",
    "fig = utils.enrichplotplot(datas_2, tags_2, size_t, color_t, xlabel, marker_types_2, figsize=(6,5),legend_color=True,legend_size=True, legend_marker=False, title='GO: Biological Component')\n",
    "fig.savefig(os.path.join(OUTPUT_DIR, 'enrichment_analysis', 'biological_component.png'), dpi=300, transparent=True)\n",
    "fig = utils.enrichplotplot(datas_3, tags_3, size_t, color_t, xlabel, marker_types_3, figsize=(6,3.5),legend_color=True,legend_size=True, legend_marker=True, title='')\n",
    "fig.savefig(os.path.join(OUTPUT_DIR, 'enrichment_analysis', 'multiple.png'), dpi=300, transparent=True, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48c69c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f566c495",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clusters = pd.read_csv(os.path.join(MAIN_DIR,'string','string_MCL_clusters.tsv'),sep='\\t')\n",
    "df_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961595e2",
   "metadata": {},
   "source": [
    "# Noncategorized "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7e0eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the time series of sig prots\n",
    "utils.plot_time_series(df, prots=sig_prots, c_tag='ctr_', s_tag='mg_', p_ID='Entry', time=specs['time'], ee=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a6eafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the sig proteins for original and imputed versions\n",
    "from scripts import utils\n",
    "candids = sig_prots[0:10]\n",
    "utils.plot_time_series_mutual(df1=df,df2=df_imput, prots=candids, )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f26d949",
   "metadata": {},
   "source": [
    "plot time serties of Moreneo's sig prots and check which ones are detected in our analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5ad14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts import utils\n",
    "importlib.reload(utils)\n",
    "moreneo_sigs = ['SDF4','NUFIP2','BUB3','HMGA2','KIF5B','DYNC1I2','DCTN1','S100A10','SYNPO2','MARCKS','THY1','HUWE1','PRPF8','RPS18','GCN1L1','RPL14','RBM8A','RPL23A','CANX','DLST','PDHB','ALDOC','APOA1','GGH','UAP1','ENO2','BAG3','HNRNPAB','BASP1','THRAP3','LRPPRC','CSE1L','PABPC4']\n",
    "utils.plot_time_series(df, prots=moreneo_sigs[0:len(moreneo_sigs)], c_tag='ctr_', s_tag='mg_', p_ID='Gene', time=specs['time'], ee=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7af932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the overlap between Moreneo's sig prots and this study\n",
    "df_overlap = df_sig.loc[df_sig['Gene'].isin(moreneo_sigs)]\n",
    "prots_overlap = df_overlap['Entry'].values\n",
    "print(prots_overlap)\n",
    "# utils.plot_time_series(df, prots=prots_overlap, c_tag='ctr_', s_tag='mg_', p_ID='Gene', time=specs['time'], ee=0.5)\n",
    "# print(prots_overlap)\n",
    "df_sig.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3fe58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputing code\n",
    "import copy\n",
    "def KNNImputer(df, n_neighbors=2): #TODO: n neighbors should be evaluated\n",
    "    from sklearn import impute\n",
    "    df_copy = copy.deepcopy(df)\n",
    "    data = df[[f'ctr_{i}' for i in time]+[f'mg_{i}' for i in time]].values\n",
    "    imputer = impute.KNNImputer(n_neighbors=n_neighbors)\n",
    "    new_data = imputer.fit_transform(data)\n",
    "    df_copy[[f'ctr_{i}' for i in time]+[f'mg_{i}' for i in time]] = new_data\n",
    "    return df_copy\n",
    "df_imput = KNNImputer(df) #TODO: this can be experimented\n",
    "for gene in df_imput['Entry'].values:\n",
    "    if df_imput.loc[df_imput['Entry']==gene].isna().values.any():\n",
    "        print('still missing values: ', gene)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "309px",
    "width": "264px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
